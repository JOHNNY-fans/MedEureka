{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nvme/wangnan/anaconda3/envs/bge_flash/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Toolkit import evaluate\n",
    "from datasets import load_from_disk\n",
    "import torch.nn as nn\n",
    "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union, cast\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from FlagEmbedding import FlagModel\n",
    "from FlagEmbedding import FlagLLMModel\n",
    "from FlagEmbedding import BGEM3FlagModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eureka_unsup = load_from_disk('./dataset/eureka_unsup_dataset')\n",
    "corpus_dict = json.loads(eureka_unsup['corpus']['task2corpus'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['task2corpus'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eureka_unsup['corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.22it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = 'BAAI/bge-multilingual-gemma2'\n",
    "# config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "# model = AutoModel.from_pretrained(model_name_or_path, config=config,ignore_mismatched_sizes=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, config=config)\n",
    "\n",
    "# model = FlagModel(model_name_or_path,use_fp16=True) \n",
    "# model = FlagLLMModel(model_name_or_path,use_fp16=True) \n",
    "# model = BGEM3FlagModel(model_name_or_path, use_fp16=True) \n",
    "model = FlagLLMModel(model_name_or_path,use_fp16=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n",
      "Inference Embeddings: 100%|██████████| 27/27 [00:07<00:00,  3.41it/s]\n",
      "Inference Embeddings: 100%|██████████| 52/52 [00:20<00:00,  2.55it/s]\n",
      "Inference Embeddings: 100%|██████████| 3/3 [00:05<00:00,  1.82s/it]\n",
      "Inference Embeddings: 100%|██████████| 139/139 [00:05<00:00, 24.14it/s]\n",
      "Inference Embeddings: 100%|██████████| 4/4 [00:01<00:00,  2.26it/s]\n",
      "Inference Embeddings: 100%|██████████| 942/942 [05:29<00:00,  2.86it/s]\n",
      "Inference Embeddings: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]\n",
      "Inference Embeddings: 100%|██████████| 261/261 [00:11<00:00, 23.29it/s]\n",
      "Inference Embeddings: 100%|██████████| 3/3 [00:01<00:00,  2.17it/s]\n",
      "Inference Embeddings: 100%|██████████| 1462/1462 [07:41<00:00,  3.17it/s]\n",
      "Inference Embeddings: 100%|██████████| 3/3 [00:06<00:00,  2.04s/it]\n",
      "Inference Embeddings: 100%|██████████| 207/207 [00:23<00:00,  8.93it/s]\n",
      "Inference Embeddings: 100%|██████████| 3/3 [00:06<00:00,  2.03s/it]\n",
      "Inference Embeddings: 100%|██████████| 1462/1462 [07:42<00:00,  3.16it/s]\n",
      "Inference Embeddings: 100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n",
      "Inference Embeddings: 100%|██████████| 121/121 [00:05<00:00, 23.78it/s]\n",
      "Inference Embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.48it/s]\n",
      "Inference Embeddings: 100%|██████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Inference Embeddings: 100%|██████████| 3/3 [00:09<00:00,  3.31s/it]\n",
      "Inference Embeddings: 100%|██████████| 59/59 [00:22<00:00,  2.58it/s]\n",
      "Inference Embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]\n",
      "Inference Embeddings: 100%|██████████| 609/609 [00:25<00:00, 23.62it/s]\n",
      "Inference Embeddings: 100%|██████████| 9/9 [00:03<00:00,  2.27it/s]\n",
      "Inference Embeddings: 100%|██████████| 1260/1260 [01:48<00:00, 11.64it/s]\n",
      "Inference Embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Inference Embeddings: 100%|██████████| 16/16 [00:00<00:00, 25.23it/s]\n",
      "Inference Embeddings: 100%|██████████| 1407/1407 [00:58<00:00, 23.90it/s]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:02<00:00,  2.48it/s]\n",
      "Inference Embeddings: 100%|██████████| 63/63 [00:11<00:00,  5.52it/s]\n",
      "Inference Embeddings: 100%|██████████| 3394/3394 [05:46<00:00,  9.81it/s]\n",
      "Inference Embeddings: 100%|██████████| 3/3 [00:07<00:00,  2.34s/it]\n",
      "Inference Embeddings: 100%|██████████| 163/163 [00:06<00:00, 24.23it/s]\n",
      "Inference Embeddings: 100%|██████████| 3/3 [00:00<00:00,  3.24it/s]\n",
      "Inference Embeddings: 100%|██████████| 1517/1517 [01:06<00:00, 22.90it/s]\n",
      "Inference Embeddings: 100%|██████████| 21/21 [00:09<00:00,  2.33it/s]\n",
      "Inference Embeddings: 100%|██████████| 65/65 [00:02<00:00, 22.71it/s]\n",
      "Inference Embeddings: 100%|██████████| 17/17 [00:06<00:00,  2.43it/s]\n",
      "Inference Embeddings: 100%|██████████| 298/298 [01:55<00:00,  2.58it/s]\n",
      "Inference Embeddings: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|                   |  HR@1  |  HR@5  | HR@10  | HR@20  | HR@50  | HR@100 | HR@200 | HR@500 |\n",
      "+-------------------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|      Study_en     | 0.3558 | 0.6043 | 0.6933 | 0.7791 | 0.9325 | 0.9908 | 1.0000 | 1.0000 |\n",
      "|      Study_zh     | 0.0000 | 0.1500 | 0.2417 | 0.3917 | 0.6833 | 0.8833 | 0.9750 | 1.0000 |\n",
      "|      Table_zh     | 0.7111 | 0.7838 | 0.8007 | 0.8108 | 0.8159 | 0.8159 | 0.8159 | 0.8176 |\n",
      "|     TwADR-L_en    | 0.3320 | 0.6144 | 0.7156 | 0.8067 | 0.8745 | 0.9211 | 0.9545 | 0.9838 |\n",
      "|     KB_para_zh    | 0.0732 | 0.5122 | 0.6280 | 0.7500 | 0.8780 | 0.9299 | 0.9451 | 0.9909 |\n",
      "|  EHR_sql2para_zh  | 0.5018 | 0.6418 | 0.6897 | 0.7394 | 0.7961 | 0.8227 | 0.8493 | 0.8865 |\n",
      "|  EHR_query2sql_zh | 0.8571 | 0.9556 | 0.9653 | 0.9778 | 0.9889 | 0.9945 | 0.9972 | 1.0000 |\n",
      "| EHR_query2para_zh | 0.5386 | 0.6702 | 0.7193 | 0.7561 | 0.8070 | 0.8298 | 0.8561 | 0.8895 |\n",
      "|     KB_doc_zh     | 0.6692 | 0.9436 | 0.9802 | 0.9924 | 0.9970 | 1.0000 | 1.0000 | 1.0000 |\n",
      "|      Table_en     | 0.8550 | 0.9703 | 0.9777 | 0.9814 | 0.9851 | 0.9926 | 1.0000 | 1.0000 |\n",
      "| Dialogue_qnorm_zh | 0.9906 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 |\n",
      "|    SMM4H-17_en    | 0.4087 | 0.7052 | 0.7965 | 0.8752 | 0.9179 | 0.9380 | 0.9548 | 0.9740 |\n",
      "|    Dialogue_en    | 0.8900 | 0.9950 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 | 1.0000 |\n",
      "|    Dialogue_zh    | 0.7267 | 0.8850 | 0.9233 | 0.9500 | 0.9867 | 0.9967 | 1.0000 | 1.0000 |\n",
      "|   AskAPatient_en  | 0.6207 | 0.8685 | 0.9294 | 0.9659 | 0.9845 | 0.9889 | 0.9911 | 0.9927 |\n",
      "|  EHR_query2doc_zh | 0.4854 | 0.6878 | 0.7317 | 0.7902 | 0.8463 | 0.8976 | 0.9366 | 0.9561 |\n",
      "|      Term_zh      | 0.4856 | 0.5701 | 0.5900 | 0.5940 | 0.6119 | 0.6209 | 0.6299 | 0.6358 |\n",
      "|     Term_cross    | 0.7180 | 0.9139 | 0.9476 | 0.9667 | 0.9821 | 0.9877 | 0.9923 | 0.9956 |\n",
      "|        Avg.       | 0.5677 | 0.7484 | 0.7961 | 0.8404 | 0.8938 | 0.9228 | 0.9388 | 0.9512 |\n",
      "+-------------------+--------+--------+--------+--------+--------+--------+--------+--------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'HR@1': '0.5677',\n",
       " 'HR@5': '0.7484',\n",
       " 'HR@10': '0.7961',\n",
       " 'HR@20': '0.8404',\n",
       " 'HR@50': '0.8938',\n",
       " 'HR@100': '0.9228',\n",
       " 'HR@200': '0.9388',\n",
       " 'HR@500': '0.9512'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model,eureka_unsup['test'],eureka_unsup['corpus'],model_type='FlagLLMModel',need_prompt_for_task=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bge_flash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
